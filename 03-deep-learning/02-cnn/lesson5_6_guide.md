# 第5-6课学习指南：卷积神经网络 (CNN)

> CNN 是图像识别的核心技术，让计算机能"看懂"图片

---

## 核心概念速览

| 概念 | 一句话解释 |
|------|-----------|
| 卷积层 | 用小滤波器扫描图片，提取局部特征 |
| 卷积核/滤波器 | 同一个东西，检测特定模式的小窗口 |
| 池化层 | 压缩图片，只保留最强特征 |
| 全连接层 | 综合所有特征，做最终决策 |

---

## 第5课：卷积层原理

### 为什么需要卷积？

普通神经网络处理图片的问题：

```
问题1：参数爆炸
    100×100 图片 × 1000神经元 = 1000万参数！

问题2：位置敏感
    猫在左边：认识
    猫在右边：不认识？
```

### 卷积的核心思想

**不看整张图，用小窗口扫描**

```
图片（大）              滤波器（小）
┌─┬─┬─┬─┬─┐           ┌─┬─┬─┐
│ │ │ │ │ │           │1│0│1│
├─┼─┼─┼─┼─┤           ├─┼─┼─┤
│ │█│█│█│ │  ←──     │0│1│0│  扫描
├─┼─┼─┼─┼─┤           ├─┼─┼─┤
│ │█│█│█│ │           │1│0│1│
└─┴─┴─┴─┴─┘           └─┴─┴─┘
```

### 卷积的两大好处

```
好处1：参数大幅减少
    普通网络：每个像素独立权重 → 1000万参数
    卷积网络：只有滤波器参数 → 几百参数

好处2：位置无关（平移不变性）
    同一个滤波器扫描整张图
    猫在哪里都能识别！
```

### 卷积核 = 从不同侧面提取特征

```
不是"拿掉"不重要的特征
而是"放大"匹配的特征

滤波器1 → 从"边缘"角度看 → 特征图1
滤波器2 → 从"纹理"角度看 → 特征图2
滤波器3 → 从"颜色"角度看 → 特征图3

多个侧面 → 完整描述这张图
```

### 深层网络的特征越来越抽象

```
第1层 → 边缘、颜色     （低级特征）
第2层 → 纹理、角点     （中级特征）
第3层 → 眼睛、鼻子     （高级特征）
第4层 → 人脸、猫脸     （语义特征）
```

---

## 第6课：池化层与特征提取

### 池化的思想：压缩

**把一小块区域变成一个数字**

```
最大池化 (Max Pooling) 2×2

输入（4×4）              输出（2×2）
┌───┬───┬───┬───┐       ┌───┬───┐
│ 1 │ 3 │ 5 │ 2 │       │   │   │
├───┼───┼───┼───┤       │ 4 │ 6 │
│ 4 │ 2 │ 6 │ 1 │  →    ├───┼───┤
├───┼───┼───┼───┤       │ 7 │ 8 │
│ 7 │ 1 │ 3 │ 8 │       │   │   │
├───┼───┼───┼───┤       └───┴───┘
│ 2 │ 5 │ 4 │ 2 │
└───┴───┴───┴───┘

每个 2×2 区域 → 取最大值
```

### 池化的好处

```
1. 减少计算量
   尺寸减半 → 数据量变成 1/4

2. 平移不变性
   只确定"有没有"特征
   不确定"在哪里"
```

### 多次池化 = 视野逐渐变大

```
原图 8×8    →  池化后 4×4  →  池化后 2×2  →  池化后 1×1
看到像素       看到小块        看到大块        看到整图

类比看地图：
1:1000（每棵树）→ 1:10000（街道）→ 1:100000（城区）
```

### CNN 的局限性

池化缩放可能导致"特征巧合"：

```
麦田纹理 → 缩小后 → 恰好像猫毛？→ 误识别！
```

解决方法：
- 多层特征综合判断
- 全连接层"把关"
- 训练数据多样性

**AI 不是100%准确，关键场景需要人工复核**

---

## 全连接层

### 什么是全连接？

**每个输入都连接到每个输出**（就是第1-4课学的普通神经网络层）

```
卷积层：局部连接，参数少，共享权重
全连接层：全部连接，参数多，不共享
```

### 在 CNN 里的作用

```
所有特征 → 加权求和 → 得出每个类别的分数 → 转成概率

[边缘特征]
[纹理特征]  →  全连接层  →  [猫:0.9, 狗:0.1]
[形状特征]
```

**全连接层 = 综合特征，做最终决策**

---

## 完整的 CNN 结构

```
输入图片 224×224×3
    ↓
┌─────────────┐
│ 卷积层 3×3  │ → 提取边缘、颜色
│ 64个滤波器  │
└─────────────┘
    ↓
┌─────────────┐
│ 池化层 2×2  │ → 压缩
└─────────────┘
    ↓
┌─────────────┐
│ 卷积层 3×3  │ → 提取纹理、形状
│ 128个滤波器 │
└─────────────┘
    ↓
┌─────────────┐
│ 池化层 2×2  │ → 压缩
└─────────────┘
    ↓
  ... 重复几次 ...
    ↓
┌─────────────┐
│ 展平        │ → 变成一维向量
└─────────────┘
    ↓
┌─────────────┐
│ 全连接层    │ → 综合所有特征
└─────────────┘
    ↓
输出：[猫: 0.9, 狗: 0.1]
```

---

## CNN 的套路总结

```
卷积 → 池化 → 卷积 → 池化 → ... → 全连接 → 输出

前半段：提取特征（卷积+池化）
后半段：做决策（全连接）
```

| 层 | 做什么 |
|---|--------|
| 卷积层 | 从不同侧面提取特征 |
| 池化层 | 压缩、扩大视野、增强鲁棒性 |
| 全连接层 | 综合特征，计算概率 |

---

## 学习检查

完成本课后，你应该能回答：

- [ ] 为什么图像识别要用卷积而不是全连接？
- [ ] 卷积核/滤波器的作用是什么？
- [ ] 池化层为什么能减少参数和增强鲁棒性？
- [ ] 多次池化后，每个点代表的区域有什么变化？
- [ ] CNN 可能出现什么问题？（特征巧合）
- [ ] 全连接层在 CNN 中的作用是什么？

---

## 下一步学习

- **第7课**：动手构建图像分类器
- **第8-10课**：人脸识别专题

---

<p align="center"><b>CNN = 卷积提特征 + 池化压缩 + 全连接做决策</b></p>
