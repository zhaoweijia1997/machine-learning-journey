# -*- coding: utf-8 -*-
"""
GPU åŠ é€Ÿå§¿æ€ä¼°è®¡ - GUI ç‰ˆæœ¬ (ä¼˜åŒ–ç‰ˆ)
å¤šçº¿ç¨‹æ•è· + GPU æ¨ç†å¹¶è¡Œ
"""

import tkinter as tk
from tkinter import ttk
import threading
import queue
import cv2
import numpy as np
import time
import os

# å…¨å±€å˜é‡
running = False
model = None

# DXCamï¼ˆæœ€å¿«çš„å±å¹•æ•è·ï¼‰
try:
    import dxcam
    HAS_DXCAM = True
except:
    HAS_DXCAM = False

try:
    import mss
    HAS_MSS = True
except:
    HAS_MSS = False


class FastScreenCapture:
    """å±å¹•æ•è· - MSS ç¨³å®šç‰ˆ"""
    def __init__(self, monitor_idx=0):
        self.monitor_idx = monitor_idx
        self.sct = None
        self.monitor = None

        if HAS_MSS:
            self.sct = mss.mss()
            monitors = self.sct.monitors
            # monitors[0] æ˜¯æ‰€æœ‰å±å¹•ï¼Œmonitors[1] æ˜¯ç¬¬ä¸€ä¸ªå±å¹•
            idx = monitor_idx + 1
            if idx < len(monitors):
                self.monitor = monitors[idx]
            else:
                self.monitor = monitors[1]

    def grab(self):
        if self.sct and self.monitor:
            try:
                img = self.sct.grab(self.monitor)
                # MSS è¿”å› BGRAï¼Œè½¬æ¢ä¸º BGR
                frame = np.array(img)
                return frame[:, :, :3].copy()
            except:
                pass
        return None

    def release(self):
        if self.sct:
            try:
                self.sct.close()
            except:
                pass
            self.sct = None


def get_monitor_count():
    if HAS_MSS:
        with mss.mss() as sct:
            return len(sct.monitors) - 1
    return 1


class PoseApp:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("å§¿æ€ä¼°è®¡ - Pose Estimation")
        self.root.geometry("400x520")
        self.root.resizable(False, False)
        self.center_window()
        self.is_running = False
        self.create_ui()

    def center_window(self):
        self.root.update_idletasks()
        w, h = 400, 520
        x = (self.root.winfo_screenwidth() - w) // 2
        y = (self.root.winfo_screenheight() - h) // 2
        self.root.geometry(f"{w}x{h}+{x}+{y}")

    def create_ui(self):
        # æ ‡é¢˜
        title_frame = tk.Frame(self.root, bg='#2c3e50', height=80)
        title_frame.pack(fill='x')
        title_frame.pack_propagate(False)

        tk.Label(title_frame, text="ğŸ¦´ å§¿æ€ä¼°è®¡ (ä¼˜åŒ–ç‰ˆ)",
                font=('Microsoft YaHei UI', 18, 'bold'),
                fg='white', bg='#2c3e50').pack(pady=20)

        main_frame = tk.Frame(self.root, padx=30, pady=15)
        main_frame.pack(fill='both', expand=True)

        # æ¨¡å¼é€‰æ‹©
        mode_frame = tk.LabelFrame(main_frame, text="è¾“å…¥æº", font=('Microsoft YaHei UI', 10))
        mode_frame.pack(fill='x', pady=8)

        self.mode_var = tk.StringVar(value='screen')

        ttk.Radiobutton(mode_frame, text="ğŸ“· æ‘„åƒå¤´",
                       variable=self.mode_var, value='camera').pack(anchor='w', padx=20, pady=3)
        ttk.Radiobutton(mode_frame, text="ğŸ–¥ï¸ å±å¹•æ•è· (DXCam åŠ é€Ÿ)",
                       variable=self.mode_var, value='screen').pack(anchor='w', padx=20, pady=3)

        # æ˜¾ç¤ºå™¨
        mon_frame = tk.Frame(mode_frame)
        mon_frame.pack(anchor='w', padx=40, pady=3)
        tk.Label(mon_frame, text="æ˜¾ç¤ºå™¨:").pack(side='left')
        self.monitor_var = tk.StringVar(value='0')
        ttk.Combobox(mon_frame, textvariable=self.monitor_var,
                    values=[str(i) for i in range(get_monitor_count())],
                    width=5, state='readonly').pack(side='left', padx=5)

        # æ€§èƒ½è®¾ç½®
        perf_frame = tk.LabelFrame(main_frame, text="æ€§èƒ½è®¾ç½®", font=('Microsoft YaHei UI', 10))
        perf_frame.pack(fill='x', pady=8)

        # åˆ†è¾¨ç‡
        res_frame = tk.Frame(perf_frame)
        res_frame.pack(fill='x', padx=20, pady=3)
        tk.Label(res_frame, text="æ¨ç†åˆ†è¾¨ç‡:").pack(side='left')
        self.resize_var = tk.StringVar(value='480')
        ttk.Combobox(res_frame, textvariable=self.resize_var,
                    values=['320', '480', '640', '720'],
                    width=8, state='readonly').pack(side='left', padx=5)
        tk.Label(res_frame, text="(320æœ€å¿«)", fg='gray').pack(side='left')

        # ç½®ä¿¡åº¦
        conf_frame = tk.Frame(perf_frame)
        conf_frame.pack(fill='x', padx=20, pady=3)
        tk.Label(conf_frame, text="ç½®ä¿¡åº¦:").pack(side='left')
        self.conf_var = tk.StringVar(value='0.5')
        ttk.Combobox(conf_frame, textvariable=self.conf_var,
                    values=['0.3', '0.4', '0.5', '0.6'],
                    width=8, state='readonly').pack(side='left', padx=5)

        # è·³å¸§
        skip_frame = tk.Frame(perf_frame)
        skip_frame.pack(fill='x', padx=20, pady=3)
        tk.Label(skip_frame, text="æ¨ç†é—´éš”:").pack(side='left')
        self.skip_var = tk.StringVar(value='1')
        ttk.Combobox(skip_frame, textvariable=self.skip_var,
                    values=['1', '2', '3'],
                    width=8, state='readonly').pack(side='left', padx=5)
        tk.Label(skip_frame, text="(æ¯Nå¸§æ¨ç†)", fg='gray').pack(side='left')

        # çŠ¶æ€
        self.status_label = tk.Label(main_frame, text="å‡†å¤‡å°±ç»ª | DXCam: " + ("âœ“" if HAS_DXCAM else "âœ—"),
                                    font=('Microsoft YaHei UI', 10), fg='#27ae60')
        self.status_label.pack(pady=8)

        # å¯åŠ¨æŒ‰é’®
        self.start_btn = tk.Button(main_frame, text="â–¶ å¯åŠ¨æ£€æµ‹",
                                  font=('Microsoft YaHei UI', 12, 'bold'),
                                  bg='#27ae60', fg='white', width=15, height=2,
                                  command=self.start_detection, cursor='hand2')
        self.start_btn.pack(pady=15)

        tk.Label(main_frame, text="æŒ‰é”®: C=æ‘„åƒå¤´ | 1-9=å±å¹• | ESC=é€€å‡º",
                font=('Microsoft YaHei UI', 9), fg='gray').pack()

    def update_status(self, text, color='#27ae60'):
        self.status_label.config(text=text, fg=color)
        self.root.update()

    def start_detection(self):
        if self.is_running:
            return
        self.is_running = True
        self.start_btn.config(state='disabled', bg='gray')
        self.update_status("åŠ è½½æ¨¡å‹...", '#f39c12')
        threading.Thread(target=self.run_detection, daemon=True).start()

    def run_detection(self):
        global model, running

        try:
            from ultralytics import YOLO

            model_path = 'yolov8n-pose_openvino_model'
            if not os.path.exists(model_path):
                self.update_status("è½¬æ¢æ¨¡å‹ä¸­...", '#f39c12')
                YOLO('yolov8n-pose.pt').export(format='openvino', half=False)

            self.update_status("åŠ è½½ä¸­...", '#f39c12')
            model = YOLO(model_path, task='pose')

            # é¢„çƒ­
            dummy = np.zeros((480, 640, 3), dtype=np.uint8)
            for _ in range(3):
                model(dummy, verbose=False)

            # å‚æ•°
            mode = self.mode_var.get()
            monitor_idx = int(self.monitor_var.get())
            resize_val = int(self.resize_var.get())
            conf_val = float(self.conf_var.get())
            skip_frames = int(self.skip_var.get())

            self.root.withdraw()
            self.detection_loop(mode, monitor_idx, resize_val, conf_val, skip_frames)

        except Exception as e:
            self.update_status(f"é”™è¯¯: {e}", '#e74c3c')
        finally:
            self.cleanup()
            self.reset_ui()

    def detection_loop(self, mode, monitor_idx, resize_val, conf_val, skip_frames):
        global model, running

        # åˆå§‹åŒ–æ•è·
        cap = None
        screen_cap = None

        if mode == 'camera':
            cap = cv2.VideoCapture(0)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            cap.set(cv2.CAP_PROP_FPS, 60)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        else:
            screen_cap = FastScreenCapture(monitor_idx)

        window_name = 'Pose [C=Cam, 1-9=Screen, ESC=Quit]'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1280, 720)

        running = True
        frame_count = 0
        start_time = time.time()
        fps = 0
        inference_times = []
        capture_times = []
        last_results = None
        last_boxes_scaled = []
        last_keypoints_scaled = []
        monitor_count = get_monitor_count()

        try:
            while running:
                try:
                    if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:
                        break
                except:
                    break

                # æ•è·
                t0 = time.perf_counter()

                if mode == 'camera' and cap:
                    ret, frame = cap.read()
                    if not ret:
                        continue
                else:
                    frame = screen_cap.grab() if screen_cap else None
                    if frame is None:
                        time.sleep(0.001)
                        continue

                cap_time = (time.perf_counter() - t0) * 1000
                capture_times.append(cap_time)
                if len(capture_times) > 30:
                    capture_times.pop(0)

                frame_count += 1
                h_orig, w_orig = frame.shape[:2]

                # æ¯ N å¸§æ¨ç†ä¸€æ¬¡
                do_inference = (frame_count % skip_frames == 0)

                if do_inference:
                    # ç¼©æ”¾
                    scale = resize_val / max(h_orig, w_orig)
                    new_w, new_h = int(w_orig * scale), int(h_orig * scale)
                    infer_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

                    t1 = time.perf_counter()
                    results = model(infer_frame, conf=conf_val, verbose=False)
                    infer_time = (time.perf_counter() - t1) * 1000

                    inference_times.append(infer_time)
                    if len(inference_times) > 30:
                        inference_times.pop(0)

                    # ç¼©æ”¾ç»“æœåˆ°åŸå§‹å°ºå¯¸
                    scale_x = w_orig / new_w
                    scale_y = h_orig / new_h

                    last_boxes_scaled = []
                    last_keypoints_scaled = []

                    if results[0].boxes is not None:
                        for box in results[0].boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            last_boxes_scaled.append((
                                int(x1 * scale_x), int(y1 * scale_y),
                                int(x2 * scale_x), int(y2 * scale_y)
                            ))

                    if results[0].keypoints is not None:
                        for kp in results[0].keypoints:
                            kp_xy = kp.xy[0].cpu().numpy().copy()
                            kp_conf = kp.conf[0].cpu().numpy() if kp.conf is not None else np.ones(17)
                            kp_xy[:, 0] *= scale_x
                            kp_xy[:, 1] *= scale_y
                            last_keypoints_scaled.append((kp_xy, kp_conf))

                # ç»˜åˆ¶
                display = frame.copy()

                # éª¨æ¶
                skeleton = [(0,1),(0,2),(1,3),(2,4),(5,6),(5,7),(7,9),(6,8),(8,10),
                           (5,11),(6,12),(11,12),(11,13),(13,15),(12,14),(14,16)]

                for kp_xy, kp_conf in last_keypoints_scaled:
                    for i, j in skeleton:
                        if kp_conf[i] > 0.5 and kp_conf[j] > 0.5:
                            pt1 = (int(kp_xy[i][0]), int(kp_xy[i][1]))
                            pt2 = (int(kp_xy[j][0]), int(kp_xy[j][1]))
                            cv2.line(display, pt1, pt2, (0, 255, 0), 2)

                    for idx, (x, y) in enumerate(kp_xy):
                        if kp_conf[idx] > 0.5:
                            cv2.circle(display, (int(x), int(y)), 5, (0, 0, 255), -1)

                for (x1, y1, x2, y2) in last_boxes_scaled:
                    cv2.rectangle(display, (x1, y1), (x2, y2), (255, 0, 0), 2)

                # FPS
                elapsed = time.time() - start_time
                fps = frame_count / elapsed if elapsed > 0 else 0

                avg_cap = sum(capture_times) / len(capture_times) if capture_times else 0
                avg_inf = sum(inference_times) / len(inference_times) if inference_times else 0

                # ä¿¡æ¯æ˜¾ç¤º
                h_disp, w_disp = display.shape[:2]
                texts = [
                    (f"FPS: {fps:.1f} | People: {len(last_keypoints_scaled)}", (0, 255, 0)),
                    (f"Cap: {avg_cap:.1f}ms | Inf: {avg_inf:.1f}ms | Skip: {skip_frames}", (0, 255, 255)),
                    (f"Mode: {'Cam' if mode=='camera' else f'Screen{monitor_idx}'} | Res: {resize_val}", (200, 200, 200))
                ]

                for i, (text, color) in enumerate(reversed(texts)):
                    sz = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
                    cv2.putText(display, text, (w_disp - sz[0] - 10, h_disp - 10 - i * 22),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

                cv2.imshow(window_name, display)

                # æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == 27 or key == ord('q'):
                    break
                elif key == ord('c') or key == ord('C'):
                    if screen_cap:
                        screen_cap.release()
                        screen_cap = None
                    if cap is None:
                        cap = cv2.VideoCapture(0)
                        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    mode = 'camera'
                elif ord('1') <= key <= ord('9'):
                    new_mon = key - ord('1')
                    if new_mon < monitor_count:
                        if cap:
                            cap.release()
                            cap = None
                        if screen_cap:
                            screen_cap.release()
                        monitor_idx = new_mon
                        screen_cap = FastScreenCapture(monitor_idx)
                        mode = 'screen'
                elif key == ord('s'):
                    cv2.imwrite(f"pose_{int(time.time())}.jpg", display)

        finally:
            if cap:
                cap.release()
            if screen_cap:
                screen_cap.release()
            cv2.destroyAllWindows()
            for _ in range(5):
                cv2.waitKey(1)

    def cleanup(self):
        pass

    def reset_ui(self):
        self.is_running = False
        self.root.deiconify()
        self.start_btn.config(state='normal', bg='#27ae60')
        self.update_status("å‡†å¤‡å°±ç»ª | DXCam: " + ("âœ“" if HAS_DXCAM else "âœ—"), '#27ae60')

    def run(self):
        self.root.mainloop()


if __name__ == "__main__":
    app = PoseApp()
    app.run()
