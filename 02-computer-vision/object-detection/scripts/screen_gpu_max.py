# -*- coding: utf-8 -*-
"""
GPU æ»¡è½½å±å¹•æ£€æµ‹ - å‹æ¦¨GPUæ€§èƒ½
ä½¿ç”¨æ›´å¤§æ¨¡å‹å’Œæ›´é«˜åˆ†è¾¨ç‡ï¼Œæœ€å¤§åŒ–GPUåˆ©ç”¨ç‡
ç”¨æ³•: python screen_gpu_max.py [model_choice] [resolution_choice]
"""

from ultralytics import YOLO
import cv2
import numpy as np
import time
import os
import sys
import argparse

try:
    import mss
except ImportError:
    print("é”™è¯¯: mss åº“æœªå®‰è£…")
    print("å®‰è£…å‘½ä»¤: pip install mss")
    sys.exit(1)

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='GPU æ»¡è½½å±å¹•æ£€æµ‹ - æ€§èƒ½å‹æ¦¨æ¨¡å¼')
    parser.add_argument('--model', type=int, choices=[1, 2, 3, 4, 5], default=3,
                       help='æ¨¡å‹é€‰æ‹©: 1=nano, 2=small, 3=medium, 4=large, 5=xlarge (é»˜è®¤=3)')
    parser.add_argument('--resolution', type=int, choices=[1, 2, 3, 4, 5], default=4,
                       help='æ¨ç†åˆ†è¾¨ç‡: 1=640, 2=1280, 3=1920, 4=2560, 5=4KåŸå§‹ (é»˜è®¤=4)')
    args = parser.parse_args()

    print("="*60)
    print("GPU æ»¡è½½å±å¹•æ£€æµ‹ - æ€§èƒ½å‹æ¦¨æ¨¡å¼")
    print("="*60)
    print()

    # è·å–æ˜¾ç¤ºå™¨ä¿¡æ¯
    sct = mss.mss()
    monitors = sct.monitors[1:]

    print("å¯ç”¨æ˜¾ç¤ºå™¨:")
    for i, mon in enumerate(monitors, 1):
        print(f"  {i}. {mon['width']}x{mon['height']} @ ({mon['left']}, {mon['top']})")

    # é»˜è®¤ä½¿ç”¨æ˜¾ç¤ºå™¨2
    monitor_idx = 2 if len(monitors) >= 2 else 1
    monitor = monitors[monitor_idx - 1]

    print(f"\nä½¿ç”¨æ˜¾ç¤ºå™¨ {monitor_idx}: {monitor['width']}x{monitor['height']}")
    print()

    # æ¨¡å‹æ˜ å°„
    model_map = {
        1: ('yolov8n', 'nano'),
        2: ('yolov8s', 'small'),
        3: ('yolov8m', 'medium'),
        4: ('yolov8l', 'large'),
        5: ('yolov8x', 'xlarge'),
    }

    model_name, model_desc = model_map[args.model]
    print(f"æ¨¡å‹: {model_name} ({model_desc})")
    print()

    # æ£€æŸ¥æ¨¡å‹
    model_path = f'{model_name}_openvino_model'
    pt_model = f'{model_name}.pt'

    if not os.path.exists(model_path):
        print(f"é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½å¹¶è½¬æ¢ {model_name} æ¨¡å‹...")
        print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
        print()

        base_model = YOLO(pt_model)
        # å¯¼å‡ºä¸º OpenVINO æ ¼å¼ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨ GPU å¦‚æœå¯ç”¨ï¼‰
        base_model.export(format='openvino', half=False)
        print()

    # åŠ è½½æ¨¡å‹å¹¶å¼ºåˆ¶ä½¿ç”¨ GPU
    print(f"åŠ è½½ {model_name} GPU ä¼˜åŒ–æ¨¡å‹...")

    # æ˜¾ç¤ºå¯ç”¨è®¾å¤‡
    try:
        from openvino import Core
        ie = Core()
        print(f"å¯ç”¨è®¾å¤‡: {ie.available_devices}")
        if 'GPU' in ie.available_devices:
            gpu_name = ie.get_property('GPU', "FULL_DEVICE_NAME")
            print(f"GPU è®¾å¤‡: {gpu_name}")
    except Exception as e:
        print(f"è·å–è®¾å¤‡ä¿¡æ¯å¤±è´¥: {e}")

    # åˆ›å»ºæ¨¡å‹æ—¶å¼ºåˆ¶æŒ‡å®š GPU è®¾å¤‡
    model = YOLO(model_path, task='detect')

    # è®¾ç½® OpenVINO æ¨ç†æ—¶ä½¿ç”¨ GPU
    print("é…ç½®ä¸ºå¼ºåˆ¶ä½¿ç”¨ GPU...")
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
    print()

    # åˆ†è¾¨ç‡æ˜ å°„
    resolution_map = {
        1: 640,
        2: 1280,
        3: 1920,
        4: 2560,
        5: None  # åŸå§‹åˆ†è¾¨ç‡
    }

    inference_size = resolution_map[args.resolution]

    if inference_size:
        print(f"\næ¨ç†åˆ†è¾¨ç‡: {inference_size}x{inference_size}")
    else:
        print(f"\næ¨ç†åˆ†è¾¨ç‡: åŸå§‹ {monitor['width']}x{monitor['height']}")
    print()

    print("="*60)
    print("æ§åˆ¶è¯´æ˜:")
    print("  ESC æˆ– q  - é€€å‡ºç¨‹åº")
    print("  s         - ä¿å­˜æˆªå›¾")
    print("  ç©ºæ ¼      - æš‚åœ/ç»§ç»­")
    print("  i         - æ˜¾ç¤º/éšè—æ€§èƒ½ä¿¡æ¯")
    print("="*60)
    print()

    # æç¤º
    print("âš ï¸  GPU æ»¡è½½æ¨¡å¼å¯åŠ¨ä¸­...")
    print("   çª—å£å°†è‡ªåŠ¨ç§»åˆ°å¦ä¸€ä¸ªæ˜¾ç¤ºå™¨")
    print()
    print("   3 ç§’åå¼€å§‹...")
    print()

    for i in range(3, 0, -1):
        print(f"   {i}...", flush=True)
        time.sleep(1)
    print("   ğŸš€ å¼€å§‹å‹æ¦¨GPUï¼")
    print()

    # åˆ›å»ºçª—å£
    window_name = f'GPU MAX - {model_name.upper()} @ {inference_size or "4K"}'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)

    # ç§»åŠ¨çª—å£åˆ°å¦ä¸€ä¸ªæ˜¾ç¤ºå™¨
    if len(monitors) >= 2:
        other_monitor = monitors[0] if monitor_idx == 2 else monitors[1]
        cv2.resizeWindow(window_name, 1920, 1080)
        cv2.moveWindow(window_name, other_monitor['left'] + 100, other_monitor['top'] + 100)
        print(f"âœ“ çª—å£å·²ç§»åŠ¨åˆ°æ˜¾ç¤ºå™¨ {1 if monitor_idx == 2 else 2}")

    print()
    print("ğŸ”¥ GPU æ»¡è½½è¿è¡Œä¸­... è§‚å¯Ÿä»»åŠ¡ç®¡ç†å™¨GPUå ç”¨ç‡ï¼")
    print()

    # ç»Ÿè®¡
    frame_count = 0
    start_time = time.time()
    fps_update_time = start_time
    current_fps = 0
    paused = False
    show_info = True

    # æ€§èƒ½ç»Ÿè®¡
    inference_times = []
    max_inference_time = 0
    min_inference_time = float('inf')

    try:
        while True:
            if not paused:
                loop_start = time.time()

                # æ•è·å±å¹•
                screenshot = sct.grab(monitor)
                frame = np.array(screenshot)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

                # å¦‚æœè®¾ç½®äº†æ¨ç†åˆ†è¾¨ç‡ï¼Œç¼©æ”¾è¾“å…¥
                if inference_size:
                    # ä¿æŒå®½é«˜æ¯”ç¼©æ”¾
                    h, w = frame.shape[:2]
                    scale = inference_size / max(h, w)
                    new_w, new_h = int(w * scale), int(h * scale)
                    inference_frame = cv2.resize(frame, (new_w, new_h))
                else:
                    inference_frame = frame

                # GPU æ¨ç† - è®°å½•æ—¶é—´
                # OpenVINO æ¨¡å‹ä¼šè‡ªåŠ¨ä½¿ç”¨åŠ è½½æ—¶æŒ‡å®šçš„è®¾å¤‡
                infer_start = time.time()
                results = model(inference_frame, verbose=False)
                infer_time = (time.time() - infer_start) * 1000  # ms

                # æ›´æ–°æ¨ç†æ—¶é—´ç»Ÿè®¡
                inference_times.append(infer_time)
                if len(inference_times) > 100:
                    inference_times.pop(0)
                max_inference_time = max(max_inference_time, infer_time)
                min_inference_time = min(min_inference_time, infer_time)
                avg_inference_time = sum(inference_times) / len(inference_times)

                # ç»Ÿè®¡äººæ•°
                person_count = sum(1 for box in results[0].boxes if int(box.cls[0]) == 0)

                # ç»˜åˆ¶ç»“æœ - åœ¨åŸå§‹å¸§ä¸Š
                annotated_frame = results[0].plot()

                # ç¼©æ”¾æ˜¾ç¤ºï¼ˆå¦‚æœæ¨ç†ç”¨çš„æ˜¯ç¼©æ”¾åçš„ï¼‰
                if inference_size and (annotated_frame.shape[1] != 1920):
                    annotated_frame = cv2.resize(annotated_frame, (1920, 1080))

                # è®¡ç®— FPS
                frame_count += 1
                current_time = time.time()

                if current_time - fps_update_time >= 1.0:
                    current_fps = frame_count / (current_time - start_time)
                    fps_update_time = current_time

                # æ˜¾ç¤ºè¯¦ç»†æ€§èƒ½ä¿¡æ¯
                if show_info:
                    info_y = 30
                    font_scale = 0.7
                    thickness = 2

                    # é»‘è‰²èƒŒæ™¯è®©æ–‡å­—æ›´æ¸…æ™°
                    overlay = annotated_frame.copy()
                    cv2.rectangle(overlay, (5, 5), (600, 250), (0, 0, 0), -1)
                    cv2.addWeighted(overlay, 0.6, annotated_frame, 0.4, 0, annotated_frame)

                    cv2.putText(annotated_frame, f"Model: {model_name.upper()} ({model_desc})",
                               (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), thickness)

                    res_text = f"{inference_size}x{inference_size}" if inference_size else f"{monitor['width']}x{monitor['height']}"
                    cv2.putText(annotated_frame, f"Resolution: {res_text}",
                               (10, info_y + 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), thickness)

                    cv2.putText(annotated_frame, f"FPS: {current_fps:.1f}",
                               (10, info_y + 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness)

                    cv2.putText(annotated_frame, f"Inference: {infer_time:.1f}ms (avg: {avg_inference_time:.1f}ms)",
                               (10, info_y + 90), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 0), thickness)

                    cv2.putText(annotated_frame, f"Min/Max: {min_inference_time:.1f}ms / {max_inference_time:.1f}ms",
                               (10, info_y + 120), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 0), thickness)

                    cv2.putText(annotated_frame, f"People: {person_count}",
                               (10, info_y + 150), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness)

                    # GPU å ç”¨æç¤º
                    cv2.putText(annotated_frame, "Check Task Manager for GPU usage!",
                               (10, info_y + 180), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 128, 0), thickness)

                cv2.imshow(window_name, annotated_frame)

            # æŒ‰é”®å¤„ç†
            key = cv2.waitKey(1) & 0xFF

            if key == 27 or key == ord('q'):
                print("\næ­£åœ¨é€€å‡º...")
                break
            elif key == ord('s'):
                filename = f"gpu_max_snapshot_{int(time.time())}.jpg"
                cv2.imwrite(filename, annotated_frame)
                print(f"å·²ä¿å­˜: {filename}")
            elif key == ord(' '):
                paused = not paused
                status = "æš‚åœ" if paused else "ç»§ç»­"
                print(status)
            elif key == ord('i'):
                show_info = not show_info
                print("æ€§èƒ½ä¿¡æ¯:", "æ˜¾ç¤º" if show_info else "éšè—")

    except KeyboardInterrupt:
        print("\næ£€æµ‹åˆ°ä¸­æ–­...")

    finally:
        # æ¸…ç†
        print("æ­£åœ¨é‡Šæ”¾èµ„æº...")
        sct.close()
        cv2.destroyAllWindows()

        for i in range(10):
            cv2.waitKey(1)

        # ç»Ÿè®¡
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time if total_time > 0 else 0

        print()
        print("="*60)
        print("GPU æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ¨¡å‹: {model_name} ({model_desc})")
        res_text = f"{inference_size}x{inference_size}" if inference_size else f"{monitor['width']}x{monitor['height']}"
        print(f"  æ¨ç†åˆ†è¾¨ç‡: {res_text}")
        print(f"  æ€»å¸§æ•°: {frame_count}")
        print(f"  è¿è¡Œæ—¶é—´: {total_time:.2f} ç§’")
        print(f"  å¹³å‡ FPS: {avg_fps:.1f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.1f} ms")
        print(f"  æ¨ç†æ—¶é—´èŒƒå›´: {min_inference_time:.1f} - {max_inference_time:.1f} ms")
        print("="*60)
        print("ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
